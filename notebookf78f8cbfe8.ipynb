{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":116092,"databundleVersionId":13860829,"sourceType":"competition"},{"sourceId":13390785,"sourceType":"datasetVersion","datasetId":8496948}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"f42e01aa","cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\n\n\ndef recall_at_k(y_true, y_prob, k=0.1):\n    \"\"\"\n    Tahmin edilen olasılıkların en üst k%'sını pozitif etiketleyerek recall değerini hesaplar.\n\n    Parametreler:\n        y_true (list): Gerçek ikili etiketler.\n        y_prob (list): Tahmin edilen olasılıklar.\n        k (float): Pozitif etiketlenecek olasılıkların yüzdelik dilimi (varsayılan 0.1).\n\n    Döndürür:\n        float: En iyi k% tahminlerindeki recall oranı.\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n\n    tp_at_k = y_true[top].sum()\n    P = y_true.sum()\n\n    return float(tp_at_k / P) if P > 0 else 0.0\n\n\ndef lift_at_k(y_true, y_prob, k=0.1):\n    \"\"\"\n    Tahmin edilen olasılıkların en üst k%'sını pozitif etiketleyerek lift (precision/prevalence) değerini hesaplar.\n\n    Parametreler:\n        y_true (list): Gerçek ikili etiketler.\n        y_prob (list): Tahmin edilen olasılıklar.\n        k (float): Pozitif etiketlenecek olasılıkların yüzdelik dilimi (varsayılan 0.1).\n\n    Döndürür:\n        float: En iyi k% tahminlerindeki lift değeri.\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_prob = np.asarray(y_prob)\n    n = len(y_true)\n    m = max(1, int(np.round(k * n)))\n    order = np.argsort(-y_prob, kind=\"mergesort\")\n    top = order[:m]\n\n    tp_at_k = y_true[top].sum()\n    precision_at_k = tp_at_k / m\n    prevalence = y_true.mean()\n\n    return float(precision_at_k / prevalence) if prevalence > 0 else 0.0\n\n\ndef convert_auc_to_gini(auc):\n    \"\"\"\n    ROC AUC skorunu Gini katsayısına dönüştürür.\n\n    Gini katsayısı, ROC AUC skorunun doğrusal bir dönüşümüdür.\n\n    Parametreler:\n        auc (float): ROC AUC skoru (0 ile 1 arasında).\n\n    Döndürür:\n        float: Gini katsayısı (-1 ile 1 arasında).\n    \"\"\"\n    return 2 * auc - 1\n\n\ndef ing_hubs_datathon_metric(y_true, y_prob):\n    \"\"\"\n    Gini, recall@10% ve lift@10% metriklerini birleştiren özel bir metrik hesaplar.\n\n    Metrik, her bir skoru bir baseline modelin metrik değerlerine göre oranlar ve aşağıdaki ağırlıkları uygular:\n    - Gini: %40\n    - Recall@10%: %30\n    - Lift@10%: %30\n\n    Parametreler:\n        y_true (list): Gerçek ikili etiketler.\n        y_prob (list): Tahmin edilen olasılıklar.\n\n    Döndürür:\n        float: Ağırlıklandırılmış bileşik skor.\n    \"\"\"\n    # final metrik için ağırlıklar\n    score_weights = {\n        \"gini\": 0.4,\n        \"recall_at_10perc\": 0.3,\n        \"lift_at_10perc\": 0.3,\n    }\n\n    # baseline modelin her bir metrik için değerleri\n    baseline_scores = {\n        \"roc_auc\": 0.6925726757936908,\n        \"recall_at_10perc\": 0.18469015795868773,\n        \"lift_at_10perc\": 1.847159286784029,\n    }\n\n    # y_prob tahminleri için metriklerin hesaplanması\n    roc_auc = roc_auc_score(y_true, y_prob)\n    recall_at_10perc = recall_at_k(y_true, y_prob, k=0.1)\n    lift_at_10perc = lift_at_k(y_true, y_prob, k=0.1)\n\n    new_scores = {\n        \"roc_auc\": roc_auc,\n        \"recall_at_10perc\": recall_at_10perc,\n        \"lift_at_10perc\": lift_at_10perc,\n    }\n\n    # roc auc değerlerinin gini değerine dönüştürülmesi\n    baseline_scores[\"gini\"] = convert_auc_to_gini(baseline_scores[\"roc_auc\"])\n    new_scores[\"gini\"] = convert_auc_to_gini(new_scores[\"roc_auc\"])\n\n    # baseline modeline oranlama\n    final_gini_score = new_scores[\"gini\"] / baseline_scores[\"gini\"]\n    final_recall_score = new_scores[\"recall_at_10perc\"] / baseline_scores[\"recall_at_10perc\"]\n    final_lift_score = new_scores[\"lift_at_10perc\"] / baseline_scores[\"lift_at_10perc\"]\n\n    # ağırlıklandırılmış metriğin hesaplanması\n    final_score = (\n        final_gini_score * score_weights[\"gini\"] +\n        final_recall_score * score_weights[\"recall_at_10perc\"] + \n        final_lift_score * score_weights[\"lift_at_10perc\"]\n    )\n    return final_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T11:38:39.659819Z","iopub.execute_input":"2025-10-15T11:38:39.660087Z","iopub.status.idle":"2025-10-15T11:38:42.506675Z","shell.execute_reply.started":"2025-10-15T11:38:39.660059Z","shell.execute_reply":"2025-10-15T11:38:42.505789Z"}},"outputs":[],"execution_count":1},{"id":"7c75e893","cell_type":"code","source":"import pandas as pd\nimport numpy as np\ntrain_data_final = pd.read_parquet('/kaggle/input/aaa222/train_data_v7.parquet')\ntest_data_final = pd.read_parquet('/kaggle/input/aaa222/test_data_v7.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T11:38:42.508548Z","iopub.execute_input":"2025-10-15T11:38:42.509029Z","iopub.status.idle":"2025-10-15T11:38:45.029174Z","shell.execute_reply.started":"2025-10-15T11:38:42.509000Z","shell.execute_reply":"2025-10-15T11:38:45.028226Z"}},"outputs":[],"execution_count":2},{"id":"1a2d5d92","cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\ntarget_col = 'churn'\ncat_features = ['gender', 'work_type', 'province', 'religion', 'work_sector']\n\ndf = train_data_final.copy()\nX_test_orig = test_data_final.copy()\nX_orig = df.drop(target_col, axis=1)\ny = df[target_col]\n#5 fold\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nlgb_params = {\n    'n_estimators': 1000,\n    'learning_rate': 0.1,\n    'max_depth': 6,\n    'reg_lambda': 3,\n    'objective': 'binary',\n    'metric': 'auc',\n    'boosting_type': 'gbdt',\n    'random_state': 42,\n    'class_weight': 'balanced',\n    'verbosity': -1\n}\n\ncatboost_params = {\n    'iterations': 1000,\n    'depth': 6,\n    'learning_rate': 0.1,\n    'l2_leaf_reg': 3,\n    'border_count': 128,\n    'random_seed': 42,\n    'eval_metric': 'AUC',\n    'verbose': 0,\n    'auto_class_weights': 'Balanced'\n}\n\n#model baslangıcı\nmodels = {\n    \"CatBoost\": (\"catboost\", catboost_params),\n    \"LightGBM\": (\"lgbm\", lgb_params),\n}\n#oof\noof_preds = {name: np.zeros(len(X_orig)) for name in models.keys()}\nfold_test_preds_dict = {name: [] for name in models.keys()}\nfor model_name, (model_type, params) in models.items():\n    print(model_name)\n    \n    for fold, (train_idx, val_idx) in enumerate(kf.split(X_orig, y), 1):\n        X_train, X_val = X_orig.iloc[train_idx].copy(), X_orig.iloc[val_idx].copy()\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n        if model_type == \"catboost\":\n            model = CatBoostClassifier(**params)\n            model.fit(X_train, y_train, cat_features=cat_features,\n                      eval_set=(X_val, y_val), early_stopping_rounds=200, verbose=0)\n        elif model_type == \"lgbm\":\n            model = lgb.LGBMClassifier(**params)\n            model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n                      categorical_feature=cat_features,\n                      callbacks=[lgb.early_stopping(200, verbose=False)])\n        y_val_pred = model.predict_proba(X_val)[:, 1]\n        oof_preds[model_name][val_idx] = y_val_pred\n\n        test_pred = model.predict_proba(X_test_orig)[:, 1]\n        fold_test_preds_dict[model_name].append(test_pred)\n\n        auc = roc_auc_score(y_val, y_val_pred)\n        custom_score = ing_hubs_datathon_metric(y_val, y_val_pred)\n        print(f\"Fold {fold} - AUC: {auc:.4f} | Custom: {custom_score:.4f}\")\n\nbase_model_test_preds = {name: np.mean(preds, axis=0) \n                         for name, preds in fold_test_preds_dict.items()}\nmeta_X = np.column_stack([oof_preds[name] for name in models.keys()])\nmeta_test_X = np.column_stack([base_model_test_preds[name] for name in models.keys()])\n\nmeta_oof_preds = np.zeros(len(y))\nmeta_test_preds_per_fold = []\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(meta_X, y), 1):\n    X_train_meta, X_val_meta = meta_X[train_idx], meta_X[val_idx]\n    y_train_meta, y_val_meta = y.iloc[train_idx], y.iloc[val_idx]\n\n    meta_model = LogisticRegression(max_iter=1000)\n    meta_model.fit(X_train_meta, y_train_meta)\n\n    y_val_meta_pred = meta_model.predict_proba(X_val_meta)[:, 1]\n    meta_oof_preds[val_idx] = y_val_meta_pred\n    meta_test_preds_per_fold.append(meta_model.predict_proba(meta_test_X)[:, 1])\n\nmeta_test_preds = np.mean(meta_test_preds_per_fold, axis=0)\n#sonuc\nfinal_auc = roc_auc_score(y, meta_oof_preds)\nprint(f\"\\n✅ Meta-classifier 5-Fold OOF AUC: {final_auc:.4f}\")\nprint(\"Meta-classifier test tahminleri hazır.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T11:38:45.030050Z","iopub.execute_input":"2025-10-15T11:38:45.030370Z","iopub.status.idle":"2025-10-15T11:43:44.880156Z","shell.execute_reply.started":"2025-10-15T11:38:45.030344Z","shell.execute_reply":"2025-10-15T11:43:44.879426Z"}},"outputs":[{"name":"stdout","text":"\n\n================= CatBoost =================\nFold 1 - AUC: 0.7236 | Custom: 1.1936\nFold 2 - AUC: 0.7197 | Custom: 1.1485\nFold 3 - AUC: 0.7156 | Custom: 1.1605\nFold 4 - AUC: 0.7208 | Custom: 1.1557\nFold 5 - AUC: 0.7252 | Custom: 1.1942\n\n\n================= LightGBM =================\nFold 1 - AUC: 0.7234 | Custom: 1.1947\nFold 2 - AUC: 0.7150 | Custom: 1.1454\nFold 3 - AUC: 0.7137 | Custom: 1.1351\nFold 4 - AUC: 0.7191 | Custom: 1.1694\nFold 5 - AUC: 0.7225 | Custom: 1.1895\n\n✅ Meta-classifier 5-Fold OOF AUC: 0.7217\nMeta-classifier test tahminleri hazır.\n","output_type":"stream"}],"execution_count":3}]}